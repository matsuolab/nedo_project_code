# Usage of Python Scripts in `test/mixtral`

## `Self_Instruct_Mixtral_For_Everyone.py`

The command below generates a jsonl file comprising datasets for Recognizing Textual Entailment (RTE) that mistralai/Mixtral-8x22B-Instruct-v0.1 produces. The LLM follows the prompt specified in `test/prompt/system_rte.md` and the prompt incorporates few-shot examples from `test/shot_sample/rte.json`.

```bash
poetry run python test/mixtral/Self_Instruct_Mixtral_For_Everyone.py --api_path="confidential/.env.local" --prompt_path="test/prompt/system_rte.md" --shot_sample_path="test/shot_sample/rte.json" --n_loop=100 --max_tokens=20000
```

## `convert_jsonl_to_json.py`

This script transforms the jsonl file, created by the aforementioned script, into a json format. The resulting data has not been manually inspected.

```bash
poetry run python test/mixtral/convert_jsonl_to_json.py --input_path="test/mixtral/data/output/generated_data_2024-05-22_14-25-39.jsonl"
```

## `fundamental_analyses.py`

This script creates a dataset for fundamental analysis of Japanese, using sentences generated by mistralai/Mixtral-8x22B-Instruct-v0.1, stored in `test/mixtral/data/input/input_human_check.txt`. Due to time constraints, only the first 50 lines have been manually reviewed. The dataset includes elements for named entity recognition, reading prediction, dependency parsing, and predicate-argument structure analysis. The `output` was generated by analyzing the sentences produced by the LLM with `ja_ginza_bert_large`, and the results of this analysis have not been manually checked.

```bash
poetry run python test/mixtral/fundamental_analyses.py --input_path="test/mixtral/data/input/input_human_check.txt"
```


# Environment settings

## CUDA installation

### [Optional] Remove existing CUDA related packages

```bash
sudo apt-get -y --purge remove nvidia*
sudo apt-get -y --purge remove cuda*
sudo apt-get -y --purge remove cudnn*
sudo apt-get -y --purge remove libnvidia*
sudo apt-get -y --purge remove libcuda*
sudo apt-get -y --purge remove libcudnn*
sudo apt-get -y autoremove
sudo apt-get -y autoclean
sudo apt-get -y update
sudo rm -rf /usr/local/cuda*
```

### Install CUDA 12.1

#### Install CUDA 12.1

```bash
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda-repo-wsl-ubuntu-12-1-local_12.1.1-1_amd64.deb
sudo dpkg -i cuda-repo-wsl-ubuntu-12-1-local_12.1.1-1_amd64.deb
sudo cp /var/cuda-repo-wsl-ubuntu-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-1
```

#### Export paths to `~/.bashrc`

DO NOT install nvcc. 

```bash
echo 'export PATH=/usr/local/cuda:/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

### Install cuDNN

```bash
wget https://developer.download.nvidia.com/compute/cudnn/9.1.1/local_installers/cudnn-local-repo-ubuntu2204-9.1.1_1.0-1_amd64.deb
sudo dpkg -i cudnn-local-repo-ubuntu2204-9.1.1_1.0-1_amd64.deb
sudo cp /var/cudnn-local-repo-ubuntu2204-9.1.1/cudnn-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cudnn-cuda-12
```

## Package installation using Poetry for developers

```bash
poetry source add torch_cu121 --priority=explicit https://download.pytorch.org/whl/cu121
poetry source add llama_cpp_python_cu121 --priority=explicit https://abetlen.github.io/llama-cpp-python/whl/cu121

poetry add torch --source torch_cu121
poetry add llama-cpp-python --source llama_cpp_python_cu121

poetry add accelerate bitsandbytes packaging ninja wheel setuptools transformers prompt2model

poetry run pip install flash-attn  --no-build-isolation
```