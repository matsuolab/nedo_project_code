{
    "model_name_or_path": "/storage4/output/culture_code" ,
    "trust_remote_code": true ,
    "tokenizer_name":"/storage4/output/culture_code" ,
    "train_file":"/storage4/datasets/pretrain/ja/wikipedia-20240101/merge/merged.jsonl",
    "output_dir":"/storage4/output/culture_code",
    "seed": 123,
    "do_train":true,
    "do_eval":false,
    "prediction_loss_only":true,
    "remove_unused_columns":false ,
    "learning_rate":5e-5 ,
    "weight_decay":0.1 ,
    "adam_beta2":0.95 ,
    "max_grad_norm": 1.0 ,
    "num_train_epochs":1 ,
    "logging_dir":"/storage4/output/JINIAC_moe",
    "logging_strategy": "steps" ,
    "logging_steps":1 ,
    "evaluation_strategy":"epoch" ,
    "save_strategy": "steps" ,
    "eval_steps": 500 ,
    "save_steps": 500,
    "load_best_model_at_end":false ,
    "save_total_limit":10 ,
    "warmup_ratio":0.1 ,
    "lr_scheduler_type":"cosine" ,
    "per_device_train_batch_size": 16 ,
    "per_device_eval_batch_size": 16 ,
    "block_size":1024 ,
    "adam_epsilon":1.0e-4 ,
    "fp16": false ,
    "bf16": true ,
    "bf16_full_eval": true ,
    "gradient_accumulation_steps":2 ,
    "push_to_hub":false,
    "dataloader_num_workers": 8,
    "optim":"adamw_torch" ,
    "torch_compile":false,
    "report_to": "wandb" ,
    "run_name": "JINIAC-5B-culturex-code0-9-lr-5e-5-aozora-wiki-5e-5" ,
    "overwrite_output_dir": true ,
    "deepspeed": "~/pretrain/config/ds_config.json" ,
    "resume_from_checkpoint": true
}