model_type: mixtral
num_experts_per_tok: 2
base_model: team-sanai/llama2_7B_pretrain
experts:
  - expert_name: "adapter_1"
    model_id: team-sanai/llama2_0.1B_lora_sample
