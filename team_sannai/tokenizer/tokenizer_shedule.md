### コーパスチーム5名の役割分担案:
- コーパス前処理担当
  - 各自が割り当てられたコーパスの前処理スクリプトを使って調整
  - 適切な前処理方法の選択と、除去ルールの決定
  - 品質評価担当
  - 前処理後のデータの品質評価
  - 前処理ルールの改善案の提示
- ドキュメンテーション担当
  - 前処理手順と除去ルールのドキュメント化
 - 進捗管理
   - 前処理作業の進捗管理と調整
### 前処理の進め方:
- コーパスごとに担当者を決め、各自で前処理スクリプトを作成
- 品質評価担当者が前処理後のデータを確認し、問題点を特定
- 除去ルールを決定し、前処理スクリプトを更新
- 更新したスクリプトを実行し、クリーンなコーパスを作成
- 品質評価を繰り返し、ルールを改善
## ステップ2: トークナイザーの学習と評価

- 学習データ・評価データの準備
  - 学習データ: 全コーパスを結合した4Gバイトのデータ
  - 日本語wiki 1.2G、英語C4 1.2G、Code 0.4G、医療0.4G、法律0.4G、数学0.4G
- 評価データ: 学習データの10%をホールドアウト
  - 0.4Gバイト
 - トークナイザーのアルゴリズム
   - t1: SentencePiece (Unigram)
   - t2: Mecab → SentencePiece (Unigram)
   - t3: SentencePiece (BPE)
   - t4: Mecab → SentencePiece (BPE)
- 評価指標
  - 未知語率 (Unk Rate)
  - 平均トークン長 (Avg Len)
  - トークン化速度 (Speed)
  - Llama 0.1B での最終損失 (Final Loss)
- 進め方
  - 前処理済みの学習データを用いて、4種類のトークナイザーを学習
  - 評価データで各トークナイザーの性能を評価し、指標を算出
  - Llama 0.1B で各トークナイザーを使ってモデルを学習
  - 最終損失を比較し、最適なトークナイザーを選定
  - 必要に応じて、ハイパーパラメータの調整を行う
## ステップ3: SMoEモデルとの統合と評価

- SMoEモデルへの統合
- 選定したトークナイザーを使って、SMoEモデルの入力データを前処理
SMoEモデルをカスタムトークナイザーに対応させるよう修正
変更後のSMoEモデルが正常に動作することを確認
SMoEモデルの評価
カスタムトークナイザーを使った SMoE と、既存トークナイザーを使った SMoE の性能を比較
評価指標: perplexity、生成文の質など
必要に応じて、トークナイザーやSMoEモデルの調整を行う
ステップ4: 進捗管理と作業の共有

$hackmdNvidia402進捗管理
22日までのスケジュールを作成する
週1回の進捗共有ミーティングを設ける
遅れが生じた場合は適宜対処し、計画の見直しを行う
作業の共有
GitHubなどを使ってスクリプトやドキュメントを共有
READMEにスクリプトの使い方と実行結果の解釈を記載
定期的にプッシュし、最新の状態を維持